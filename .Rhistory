par(mfrow=c(2,2)); plot(fit_lm)
par(mfrow=c(1,1))
summary(fit_lm)
summary(fit_les)
summary(fit_less)
fit_less2=lm(mpg ~ wt + qsec + factor(am), data=mtcars)
summary(fit_less2)
summary(lm(mpg ~ factor(cyl) + disp + hp + drat + wt + qsec + factor(vs) + factor(am) + factor(gear) + factor(carb), data=mtcars))
summary(lm(mpg ~ disp + hp + drat + wt + qsec + factor(vs) + factor(am) + factor(gear) + factor(carb), data=mtcars))
summary(lm(mpg ~ disp + hp + drat + wt + qsec + factor(vs) + factor(am) + factor(gear), data=mtcars))
summary(lm(mpg ~ disp + hp + drat + wt + qsec + factor(vs) + factor(am), data=mtcars))
summary(lm(mpg ~ disp + hp + drat + wt + qsec + factor(am), data=mtcars))
summary(lm(mpg ~ disp + hp + wt + qsec + factor(am), data=mtcars))
summary(lm(mpg ~ hp + wt + qsec + factor(am), data=mtcars))
summary(lm(mpg ~  wt + qsec + factor(am), data=mtcars))
summary(fit_less2)
confint(fit_imp))
resids=residuals(fit_imp)
hist(mtcars$am)
par(mfrow=c(1,1))
hist(mtcars$am)
sum(mtcars$am[mtcars$am==1])
sum(mtcars$am[mtcars$am==0])
sum(mtcars$am[mtcars$am==2])
mtcars$am
length(mtcars$am[mtcars$am==0])
19+13
hist(mpg, data=mtcars, main='Figure 1: Histogram of MPG', ylab="Frequency", xlab="Miles Per Gallon")
hist(mtcars$mpg, main='Figure 1: Histogram of MPG', ylab="Frequency", xlab="Miles Per Gallon")
The goal of this work is to determine whether there is a statistically significant difference between the miles per gallon (mpg) of a car and the type of transmission (manual or automatic) in the car and quantify the difference. We have analyzed data from Motor Trend 1974 that includes 11 different aspects of automobile design and performance for 32 cars and have determined that there is a statistically significant difference in the fuel efficiency of manual versus automatic transmissions. Initially, we take into account all 11 possible predictive variables to explain the measured outcome of mpg. Using the stepwise backwards elimination method for model selection, we determine a generalized linear model of multiple regression using weight, quarter mile time, and transmission type to predict the achieved mpg. With a p-value of less than 0.05, we can be 95% confident that there is a statistical difference between the two transmissions. From this dataset, we predict an average increase of approximately 2.94 MPG when using a manual transmission over an automatic tranmission, with a 95% confidence interval of (0.171, 5.70). However, we warn that the conclusions in this report can not be used to make any suggestions about modern day transmissions in cars. We suggest that future studies be designed as pairwise tests to best determine any possible fuel efficiency differences due to transmission type.
fit_lm=lm(mpg ~ factor(am), data=mtcars)
summary(fit_lm)$coeff
fit_all=glm(mpg ~ factor(cyl) + disp + hp + drat + wt + qsec + factor(vs)+factor(am)+factor(gear)+factor(carb), data=mtcars)
fit_imp=glm(mpg ~ wt + qsec + factor(am), data=mtcars)
summary(fit_imp)$coeff
confint(fit_imp)
hist(mtcars$mpg, main='Figure 1: Histogram of MPG', ylab="Frequency", xlab="Miles Per Gallon")
boxplot(mpg ~ am, data=mtcars, main='Figure 2: MPG vs Transmission Type', xlab="Automatic (0) vs. Manual (1)", ylab="Miles Per Gallon")
par(mfrow=c(2,2))
plot(fit_lm)
par(mfrow=c(2,2))
plot(fit_imp)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages(AppliedPredictiveModeling)
install.packages(caret)
installed.packages
installed.packages()
install.packages("caret")
install.packages("AppliedPredictiveModeling")
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(AlzheimerDisease)
library(AppliedPredictiveMdeling)
library(AppliedPredictiveModeling)
library(caret)
adData = data.frame(diagnosis,predictors,data=Al)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors,data=AlzehimerDisease)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors,data=AlzheimerDisease)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
AlzheimerDisease=data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors,data=AlzheimerDisease)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
length(concrete)
concrete
xx=1:1030
plot(xx,training$CompressiveStrength)
xx=1:1031
plot(xx,training$CompressiveStrength)
head(concrete)
xx
length(concrete$CompressiveStrength)
xx
xx=1:1030
plot(xx,training$CompressiveStrength)
length(concrete$CompressiveStrength)
length(xx)
plot(training$CompressiveStrength)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
boxplot(concrete$Superplasticizer)
hist(concrete$Superplasticizer)
set.seed(3433)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(adData)
preObj = preProcess(training[58:69],)
preObj = preProcess(training[58:69],thresh=.8)
preObj
preObj2 = preProcess(training[58:69], method='lm')
preObj2 = preProcess(training[58:69], method='glm')
modelFit=train(preObj,method='glm')
modelFit=train(preObj[58:69],method='glm')
modelFit=train(training$diagnosis~preObj[58:69],method='glm',)
modelFit=train(training$diagnosis~preObj$[58:69],method='glm')
modelFit=train(training$diagnosis ~ preObj, subset=[58:69],method='glm')
modelFit=train(training$diagnosis ~ .,Â method='glm',preProcess=training[58:69] )
modelFit=train(training$diagnosis ~ ., method='glm',preProcess=training[58:69])
modelFit=train(training$diagnosis ~ ., method='glm',preProcess=training[58:69], data=training)
modelFit=train(training$diagnosis ~ ., method='glm', data=preObj)
modelFit=train(training$diagnosis ~ ., method='glm', data=preObj)
modelFit=train(training$diagnosis ~ ., method='glm', data=training[58:69])
library(e1071)
install.packages("e1071")
library(e1071)
modelFit=train(training$diagnosis ~ ., method='glm', data=training[58:69])
modelFit
modelFit2=train(training$diagnosis ~ ., method='pca', data=training[58:69])
modelFit2=train(training$diagnosis ~ ., method='pca', data=training[58:69],pcaComp=2)
ibrary(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
inTrain = createDataPartition(segmentationOriginal$Case, p=0.6, list=FALSE)
seed(125)
set.seed(125)
inTrain = createDataPartition(segmentationOriginal$Case, p=0.6, list=FALSE)
training = segmentationOriginal[inTrain,]
test = segmentationOriginal[-inTrain,]
modelFit = train(segmentationOriginal$Case~.,method='rpart')
modelFit = train(Case~.,method='rpart',data=training)
modelFit
modelFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
plot(modelFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
text(modelFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(rpart)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
install.packages(rattle)
install.packages("rattle")
library(rattle)
install.packages(rattle)
fancyRpartPlot(modelFit$finalModel)
fancyRpartPlot(modelFit)
predData[1,c(103,50,85)]=c(23000,10,2)
predData <- training[1:3,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
#TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
#FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(modelFit,predData)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain_oil = createDataPartition(olive$Area, p=0.6, list=FALSE)
training_oil = olive[inTrain_oil,]
test_oil = olive[-inTrain_oil,]
modelFit_oil = train(olive$Area~.,method='rpart')
inTrain_oil = createDataPartition(olive$Area, p=0.6, list=FALSE)
training_oil = olive[inTrain_oil,]
test_oil = olive[-inTrain_oil,]
modelFit_oil = train(training$Area~.,method='rpart',)
inTrain_oil = createDataPartition(olive$Area, p=0.6, list=FALSE)
training_oil = olive[inTrain_oil,]
test_oil = olive[-inTrain_oil,]
modelFit_oil = train(Area~.,method='rpart',data=training)
inTrain_oil = createDataPartition(olive$Area, p=0.6, list=FALSE)
training_oil = olive[inTrain_oil,]
test_oil = olive[-inTrain_oil,]
modelFit_oil = train(Area~.,method='rpart',data=training_oil)
newdata = as.data.frame(t(colMeans(olive)))
pred_oil = predict(modelFit_oil,newdata=newdata)
pred_oil
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA = train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predictionSA=predict(modelSA,SAheart)
missClass = function(trainSA,predictionSA){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
sum(((predictionSA > 0.5)*1) != values)/length(trainSA)
sum(((predictionSA > 0.5)*1) != trainSA)/length(trainSA)
predictionSA=predict(modelSA,trainSA)
sum(((predictionSA > 0.5)*1) != trainSA)/length(trainSA)
missClass(trainSA$chd,predict(modelSA,trainSA))
missClass = function(trainSA,predictionSA){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(modelSA,trainSA))
missClass(trainSA$chd,predictionsSA)
sum(((predictionSA > 0.5)*1) != trainSA$chd)/length(trainSA$chd)
sum(((predictionSA > 0.5)*1) != testSA$chd)/length(testSA$chd)
set.seed(13234)
modelSA = train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,method="glm",family="binomial")
predictionSA=predict(modelSA,trainSA)
sum(((predictionSA > 0.5)*1) != trainSA$chd)/length(trainSA$chd)
predictionSA=predict(modelSA,testSA)
sum(((predictionSA > 0.5)*1) != testSA$chd)/length(testSA$chd)
data(vowel.train)
data(vowel.test)
vowel.test$y <-as.factor(vowel.test$y)
vowel.train$y <-as.factor(vowel.train$y)
set.seed(33833)
vowelFit = train(y~., data=vowel.train, method="rf")
varImp(vowelFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
mod1=train(vowel.train$y~.,method='rf')
library(caret)
mod1=train(vowel.train$y~.,method='rf')
mod1=train(y~.,method='rf', data=vowel.train)
mod2=train(y~.,method='gbm', data=vowel.train)
mod1pred=predict(mod1,vowel.train)
mod2pred=predict(mod2,vowel.train)
confusionMatrix(vowel.train$y[mod1pred==mod2pred],mod1pred)
confusionMatrix(vowel.train$y[mod1pred==mod2pred],mod2pred)
test1pred=predict(mod1,vowel.test)
test2pred=predict(mod2,vowel.test)
confusionMatrix(vowel.test$y[mod1pred==mod2pred],test2pred)
confusionMatrix(vowel.test$y[test1pred==test2pred],test2pred)
dim(vowel.test$y)
dim(vowel.test)
dim(test1pred)
test1pred
test2pred
vowel.test$y
confusionMatrix(vowel.test$y[test1pred==test2pred],test2pred[test1pred==test2pred])
confusionMatrix(vowel.test$y[test1pred==test2pred],test1pred[test1pred==test2pred])
confusionMatrix(vowel.test$y,test1pred)
confusionMatrix(vowel.test$y,test2pred)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1=train(diagnosis~.,method="rf",data=adData)
mod1=train(diagnosis~.,method="gbm",data=adData)
mod1=train(diagnosis~.,method="rf",data=adData)
mod2=train(diagnosis~.,method="gbm",data=adData)
mod3=train(diagnosis~.,method="lda",data=adData)
predDF=data.frame(mod1,mod2,mod3)
predDF=data.frame(mod1,mod2,mod3,diagnosis=testing$diagnosis)
pred1=predict(mod1, data=testing)
pred1=predict(mod1, data=training)
pred1=predict(mod1, data=testing)
pred1
pred1=predict(mod1, data=testing$diagnosis)
pred1=predict(mod1, data=testing)
pred1=predict(mod1,testing)
pred2=predict(mod2,testing)
pred3=predict(mod3,testing)
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combFit=train(diagnosis~., method="rf",data=predDF)
combPred=predict(combFit,predDF)
confusionMatrix(combPred,adData$diagnosis)
confusionMatrix(adData$diagnosis,combPred)
dim(adData$diagnosis)
adData$diagnosis
dim(combPred)
combPred
confusionMatrix(test$diagnosis,combPred)
confusionMatrix(testing$diagnosis,combPred)
mod1=train(diagnosis~.,method="rf",data=training)
set.seed(62433)
mod1=train(diagnosis~.,method="rf",data=training)
mod2=train(diagnosis~.,method="gbm",data=training)
mod3=train(diagnosis~.,method="lda",data=training)
pred1=predict(mod1,testing)
pred2=predict(mod2,testing)
pred3=predict(mod3,testing)
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combFit=train(diagnosis~., method="rf",data=predDF)
combPred=predict(combFit,predDF)
confusionMatrix(combPred,adData$diagnosis)
confusionMatrix(testing$diagnosis,combPred)
confusionMatrix(testing$diagnosis,pred1)
confusionMatrix(testing$diagnosis,pred2)
confusionMatrix(testing$diagnosis,pred3)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod1=train(training,method="lasso")
mod1=train(training,method="lasso")
mod1=train(CompressiveStrength ~ ., data=training,method="lasso")
plot.enet(mod1$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library("forecast")
install.packages(forecast)
install.packages("forecast")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod1 = train(CompressiveStrength~., method="svm", data=concrete)
install.packages("svm")
library(e1071)
mod1 = train(CompressiveStrength~., method="svm", data=concrete)
mod1 = train(CompressiveStrength~., method="svmRadial", data=concrete)
mod1 = train(CompressiveStrength~., method="svmRadial", data=concrete)
pred1=predict(mod1,testing)
accuracy(pred1,testing$CompressiveStrength)
confusionMatrix(pred1,testing$CompressiveStrength)
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
sqrt(sum((pred1 - testing$CompressiveStrength)^2))
sqrt(mean((pred1 - testing$CompressiveStrength)^2))
install.packages("shiny")
library(shiny)
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
devtools::install_github('rstudio/shinyapps')
library(devtools)
install.packages("devtools")
library("devtools")
library(devtools)
library(devtools)
install.packages("devtools",suppressMessages=TRUE)
library(devtools)
install.packages("devtools",suppressMessages=TRUE)
getDependencies()
install.packages("devtools")
install.packages("devtools",source='/Library/Frameworks/R.framework/Resources/library/devtools/inst/templates//packagename-package.r'
)
install.packages("devtools",source='/Library/Frameworks/R.framework/Versions//3.0//Resources//library/devtools//inst//templates')
install.packages("devtools",source='/Library/Frameworks/R.framework/Versions//3.0//Resources//library/devtools//inst//templates/packagename-package.r')
install.packages('/Library/Frameworks/R.framework/Versions//3.0//Resources//library/devtools//inst//templates/packagename-package.r')
install.packages('/Library/Frameworks/R.framework/Versions//3.0//Resources//library/devtools/')
install.packages("devtools_1.4.1.tar.gz")
install.packages("devtools_1.4.1.tar.gz", repos = NULL)
install.packages("devtools_1.4.1.tar.gz", repos = NULL,type=source)
install.packages("Downloads/devtools_1.6.1.tgz", repos = NULL)
library(devtools)
install_github('rstudio/shinyapps')
library(shiny)
runExample("01_hello")
setwd("/Users/rachelwk82/Documents/UF/Coursera/Data Science/9 - Developing Data Products/p")
setwd("/Users/rachelwk82/Documents/UF/Coursera/Data Science/9 - Developing Data Products/Project/")
runApp()
library(shiny)
runApp()
runApp()
library(ggplot)
library(ggplot2)
ggplot(data=swiss)
ggplot(Education,Examination,data=swiss)
ggplot(swiss$Education,swiss$Examination)
ggplot(swiss$Education~swiss$Examination)
ggplot(swiss, aes(Examination, Education, group=Catholic, color=Catholic))
ggplot(swiss, aes(Examination, Education, group=Catholic, color=Catholic),geom_point())
p=ggplot(swiss, aes(Examination, Education, group=Catholic, color=Catholic))
p=p + geom_point()
print p
print(p)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
p=ggplot(swiss, aes(Examination, Education, group=Catholic, color=Catholic))+geom_point()
print(p)
p=ggplot(swiss, aes(Fertility, Agriculture, group=Catholic, color=Catholic))+geom_point()
print(p)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("test")
runApp()
getwd()
runApp()
setwd("..")
getwd()
setwd("/Users/rachelwk82/Documents/UF/Coursera/Data Science/9 - Developing Data Products/Project/")
getwd()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
